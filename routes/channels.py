"""
Channels 管理路由
"""

import os
import json
import copy

from core.env import env_bool
import httpx
from time import time
from typing import Optional, Any

from fastapi import APIRouter, Depends, HTTPException, Body
from fastapi.responses import JSONResponse

from core.channels import list_channels, get_channel
from core.log_config import logger
from utils import safe_get
from routes.deps import rate_limit_dependency, verify_admin_api_key, get_app

router = APIRouter()
is_debug = env_bool("DEBUG", False)


def _mask_api_key(key: str) -> str:
    s = str(key or "")
    if not s:
        return ""
    if len(s) <= 11:
        return s
    return f"{s[:7]}...{s[-4:]}"


def _is_invalid_api_key(upstream_status: Optional[int], error_detail: str = "") -> bool:
    """通用规则判断 key 是否失效（用于自动禁用的建议）。"""

    if upstream_status is None:
        return False

    text = (error_detail or "").lower()

    if upstream_status in (401, 403):
        # 常见：余额/额度问题，不应直接禁用
        if any(x in text for x in ("insufficient_quota", "quota", "billing", "credit", "余额", "额度")):
            return False
        # 常见：限流，不应直接禁用
        if any(x in text for x in ("rate limit", "too many requests", "限流", "频率")):
            return False
        return True

    # 部分网关会把 invalid api key 映射为 400
    if upstream_status == 400 and any(x in text for x in ("invalid api key", "invalid_api_key", "api key invalid")):
        return True

    return False


async def _perform_channel_test_request(
    *,
    app: Any,
    engine: str,
    provider: dict,
    api_key: Optional[str],
    model: str,
    upstream_model_hint: Optional[str],
    timeout: int,
    proxy: Optional[str],
) -> dict:
    """执行一次上游测试请求，返回结构化结果（不抛异常）。"""

    from core.request import get_payload
    from core.models import RequestModel

    start_time = time()

    try:
        test_request = RequestModel(
            model=model,
            messages=[{"role": "user", "content": "Hi"}],
            max_tokens=1000,
            stream=False,
        )

        url, headers, payload = await get_payload(test_request, engine, provider, api_key)

        # 对齐正式链路：追加渠道自定义 headers
        custom_headers = safe_get(provider, "preferences", "headers", default={})
        if isinstance(custom_headers, dict):
            headers.update({str(k): str(v) for k, v in custom_headers.items() if v is not None})

        if is_debug:
            try:
                pretty_payload = json.dumps(payload, ensure_ascii=False)
            except Exception:
                pretty_payload = str(payload)
            logger.info(f"Channel test - Engine: {engine}")
            logger.info(f"Channel test - URL: {url}")
            logger.info(f"Channel test - Headers: {headers}")
            logger.info(f"Channel test - Payload (truncated): {pretty_payload[:2000]}")

        async with app.state.client_manager.get_client(url, proxy) as client:
            response = await client.post(
                url,
                headers=headers,
                json=payload,
                timeout=timeout,
            )

        latency_ms = int((time() - start_time) * 1000)
        upstream_status_code = response.status_code

        resp_json = None
        error_detail = ""
        upstream_error_code: Optional[str] = None

        try:
            resp_json = response.json()
        except Exception:
            resp_json = None

        if isinstance(resp_json, dict):
            if resp_json.get("error") is not None:
                err_obj = resp_json.get("error")
                if isinstance(err_obj, dict):
                    upstream_error_code = err_obj.get("code") or err_obj.get("type")
                    error_detail = (
                        err_obj.get("message")
                        or err_obj.get("code")
                        or err_obj.get("status")
                        or str(err_obj)
                    )
                else:
                    error_detail = str(err_obj)
            elif resp_json.get("detail") and not resp_json.get("choices"):
                error_detail = str(resp_json.get("detail"))

        if not error_detail:
            try:
                body_text = response.text
                if body_text and body_text.strip() and response.status_code >= 400:
                    error_detail = body_text[:500]
            except Exception:
                pass

        is_success = 200 <= upstream_status_code < 300 and not error_detail
        invalid_key = _is_invalid_api_key(upstream_status_code, error_detail)

        if is_success:
            return {
                "success": True,
                "latency_ms": latency_ms,
                "upstream_status_code": upstream_status_code,
                "upstream_error_code": upstream_error_code,
                "is_invalid_api_key": False,
                "message": "测试成功",
                "error": None,
            }

        if not error_detail:
            error_detail = f"HTTP {upstream_status_code}"

        return {
            "success": False,
            "latency_ms": latency_ms,
            "upstream_status_code": upstream_status_code,
            "upstream_error_code": upstream_error_code,
            "is_invalid_api_key": invalid_key,
            "message": f"HTTP {upstream_status_code}",
            "error": error_detail,
        }

    except httpx.TimeoutException:
        latency_ms = int((time() - start_time) * 1000)
        return {
            "success": False,
            "latency_ms": latency_ms,
            "upstream_status_code": None,
            "upstream_error_code": None,
            "is_invalid_api_key": False,
            "message": "请求超时",
            "error": f"请求超时（{timeout}秒）",
        }
    except httpx.ConnectError as e:
        return {
            "success": False,
            "latency_ms": None,
            "upstream_status_code": None,
            "upstream_error_code": None,
            "is_invalid_api_key": False,
            "message": "连接失败",
            "error": str(e),
        }
    except Exception as e:
        latency_ms = int((time() - start_time) * 1000) if time() - start_time > 0 else None
        error_message = str(e)

        response = getattr(e, "response", None)
        if response is not None:
            try:
                error_data = response.json()
                if isinstance(error_data, dict):
                    err_obj = error_data.get("error")
                    if isinstance(err_obj, dict):
                        error_message = err_obj.get("message") or err_obj.get("code") or str(err_obj)
                    else:
                        error_message = (
                            error_data.get("message")
                            or error_data.get("detail")
                            or str(error_data)
                        )
            except Exception:
                pass

        logger.error(f"Channel test failed: {error_message}")
        if is_debug:
            import traceback
            traceback.print_exc()

        return {
            "success": False,
            "latency_ms": latency_ms,
            "upstream_status_code": None,
            "upstream_error_code": None,
            "is_invalid_api_key": False,
            "message": "测试失败",
            "error": error_message,
        }


@router.get("/v1/channels", dependencies=[Depends(rate_limit_dependency)])
async def get_channels(token: str = Depends(verify_admin_api_key)):
    """
    获取所有已注册的渠道类型列表。
    返回每个渠道的 id, type_name, default_base_url, auth_header, description, has_models_adapter。
    """
    channels = list_channels()
    channel_list = [ch.to_dict() for ch in channels]
    return JSONResponse(content={"channels": channel_list})


@router.post("/v1/channels/fetch_models", dependencies=[Depends(rate_limit_dependency)])
async def fetch_channel_models(
    token: str = Depends(verify_admin_api_key),
    provider_config: dict = Body(..., description="Provider configuration including engine, base_url, api_key, etc.")
):
    """
    根据渠道配置获取可用的模型列表。
    
    请求体示例:
    {
        "engine": "gpt",  // 渠道类型 ID
        "base_url": "https://api.openai.com/v1",
        "api_key": "sk-xxx",
        // 其他渠道特定配置...
    }
    
    返回:
    {
        "models": ["gpt-4", "gpt-3.5-turbo", ...]
    }
    """
    app = get_app()
    
    engine = provider_config.get("engine") or provider_config.get("type") or "openai"
    
    # 获取渠道定义
    channel = get_channel(engine)
    if not channel:
        raise HTTPException(status_code=404, detail=f"Channel type '{engine}' not found")
    
    if not channel.models_adapter:
        raise HTTPException(status_code=400, detail=f"Channel '{engine}' does not support fetching models")
    
    # 构建 provider 配置，如果 base_url 为空则使用渠道默认值
    config_base_url = provider_config.get("base_url", "")
    provider = {
        "base_url": config_base_url if config_base_url else (channel.default_base_url or ""),
        "api": provider_config.get("api_key") or provider_config.get("api") or "",
        # Vertex AI 特定配置
        "project_id": provider_config.get("project_id", ""),
        "client_email": provider_config.get("client_email", ""),
        "private_key": provider_config.get("private_key", ""),
        # AWS 特定配置
        "aws_access_key": provider_config.get("aws_access_key", ""),
        "aws_secret_key": provider_config.get("aws_secret_key", ""),
        # Cloudflare 特定配置
        "cf_account_id": provider_config.get("cf_account_id", ""),
    }
    
    # 获取代理配置
    proxy = provider_config.get("proxy") or safe_get(app.state.config, "preferences", "proxy")
    
    # 验证 base_url 格式
    base_url = provider.get("base_url", "")
    if base_url and not base_url.startswith(("http://", "https://")):
        # 自动添加 https:// 前缀
        provider["base_url"] = f"https://{base_url}"
        logger.info(f"Auto-prefixed base_url: {provider['base_url']}")
    
    try:
        async with app.state.client_manager.get_client(provider["base_url"], proxy) as client:
            # 设置超时，避免请求卡死
            import asyncio
            models = await asyncio.wait_for(
                channel.models_adapter(client, provider),
                timeout=30.0
            )
            return JSONResponse(content={"models": models})
    except Exception as e:
        # 尽量提取并返回上游的错误信息
        upstream_status = None
        upstream_message: Optional[str] = None

        response = getattr(e, "response", None)
        if response is not None:
            try:
                upstream_status = response.status_code
            except Exception:
                upstream_status = None

            try:
                data = response.json()
                if isinstance(data, dict):
                    upstream_message = (
                        data.get("error")
                        or data.get("message")
                        or data.get("detail")
                    )
                else:
                    upstream_message = str(data)
            except Exception:
                try:
                    upstream_message = response.text
                except Exception:
                    upstream_message = None

        if not upstream_message:
            upstream_message = str(e).split("For more information")[0].strip()

        logger.error(
            f"Failed to fetch models for channel '{engine}': "
            f"status={upstream_status}, error={upstream_message}, raw_exception={repr(e)}"
        )
        if is_debug:
            import traceback
            traceback.print_exc()

        status_code = upstream_status or 502
        raise HTTPException(
            status_code=status_code,
            detail=f"上游接口返回错误 ({status_code}): {upstream_message}"
        )


@router.post("/v1/channels/test", dependencies=[Depends(rate_limit_dependency)])
async def test_channel(
    token: str = Depends(verify_admin_api_key),
    test_config: dict = Body(..., description="Test configuration including provider snapshot and model to test")
):
    """
    测试特定渠道的连接。

    目标：尽量复用正式请求链路，避免测试链路与生产链路行为不一致。
    - 支持传入 provider_snapshot（完整渠道配置）
    - 保持对旧字段（engine/base_url/api_key/model）的兼容
    - 支持 preferences.headers / post_body_parameter_overrides / enabled_plugins
    
    请求体示例:
    {
        "provider_snapshot": { ...完整渠道配置... },
        "model": "gpt-4o-mini",  // 建议传模型别名
        "upstream_model": "gpt-4o-mini",  // 可选，别名缺失时回退
        "timeout": 30,

        // 兼容旧用法（可选）
        "engine": "openai",
        "base_url": "https://api.openai.com/v1",
        "api_key": "sk-xxx"
    }
    """
    from core.utils import get_model_dict

    def _normalize_key_item(item: Any) -> Optional[str]:
        if isinstance(item, str):
            key = item.strip()
            return key or None
        if isinstance(item, dict):
            key = item.get("key")
            if isinstance(key, str) and key.strip():
                key = key.strip()
                if item.get("disabled") and not key.startswith("!"):
                    key = f"!{key}"
                return key
        return None

    def _collect_key_candidates(raw_keys: Any) -> list[str]:
        if raw_keys is None:
            return []
        items = raw_keys if isinstance(raw_keys, list) else [raw_keys]
        results: list[str] = []
        for item in items:
            normalized = _normalize_key_item(item)
            if normalized:
                results.append(normalized)
        return results
    
    app = get_app()

    provider_snapshot = test_config.get("provider_snapshot")
    provider = copy.deepcopy(provider_snapshot) if isinstance(provider_snapshot, dict) else {}
    if not isinstance(provider, dict):
        provider = {}

    engine = (
        test_config.get("engine")
        or provider.get("engine")
        or test_config.get("type")
        or "openai"
    )
    engine = str(engine).strip() if engine is not None else "openai"

    model = (
        test_config.get("model")
        or test_config.get("model_alias")
        or test_config.get("upstream_model")
        or ""
    )
    model = str(model).strip()

    upstream_model_hint = test_config.get("upstream_model")
    upstream_model_hint = str(upstream_model_hint).strip() if upstream_model_hint else None

    if not model:
        raise HTTPException(status_code=400, detail="model 是必填项")

    timeout = test_config.get("timeout", 30)
    try:
        timeout = max(1, int(timeout))
    except Exception:
        timeout = 30

    channel = get_channel(engine)
    if not channel:
        raise HTTPException(status_code=404, detail=f"Channel type '{engine}' not found")

    provider["provider"] = provider.get("provider") or f"test_{engine or 'channel'}"
    provider["engine"] = engine

    base_url = test_config.get("base_url") or provider.get("base_url", "")
    base_url = str(base_url).strip() if base_url else ""

    # 如果 base_url 为空，使用渠道默认值
    if not base_url:
        if channel.default_base_url:
            base_url = channel.default_base_url
            logger.info(f"Using default base_url for channel '{engine}': {base_url}")
        else:
            raise HTTPException(status_code=400, detail="base_url 是必填项（该渠道类型没有默认地址）")

    # 验证 base_url 格式
    if not base_url.startswith(("http://", "https://")):
        # 自动添加 https:// 前缀
        base_url = f"https://{base_url}"
        logger.info(f"Auto-prefixed base_url: {base_url}")
    provider["base_url"] = base_url.rstrip('/')

    # 解析测试使用 API Key：显式传参 > provider.api / provider.api_keys
    explicit_api_key = test_config.get("api_key") or test_config.get("api")
    selected_api_key = None
    if isinstance(explicit_api_key, str) and explicit_api_key.strip():
        selected_api_key = explicit_api_key.strip()
        if selected_api_key.startswith("!"):
            selected_api_key = selected_api_key[1:]
    else:
        candidates = _collect_key_candidates(provider.get("api"))
        candidates.extend(_collect_key_candidates(provider.get("api_keys")))

        for key in candidates:
            if not key.startswith("!"):
                selected_api_key = key
                break

        if not selected_api_key and candidates:
            selected_api_key = candidates[0][1:] if candidates[0].startswith("!") else candidates[0]

    if selected_api_key:
        provider["api"] = selected_api_key

    # 确保模型映射存在，兼容别名测试
    provider_models = provider.get("model")
    if not isinstance(provider_models, list):
        fallback_models = provider.get("models")
        provider_models = copy.deepcopy(fallback_models) if isinstance(fallback_models, list) else []

    if not provider_models:
        if upstream_model_hint and upstream_model_hint != model:
            provider_models = [{upstream_model_hint: model}]
        else:
            provider_models = [model]

    provider["model"] = provider_models
    provider.pop("models", None)

    model_dict = get_model_dict(provider)
    if model not in model_dict:
        if upstream_model_hint and upstream_model_hint != model:
            provider["model"].append({upstream_model_hint: model})
        else:
            provider["model"].append(model)
        model_dict = get_model_dict(provider)

    provider["_model_dict_cache"] = model_dict

    if model not in model_dict:
        raise HTTPException(status_code=400, detail=f"model '{model}' 不在当前渠道模型配置中")

    # 获取代理配置（优先级：test_config > provider > global）
    proxy = test_config.get("proxy")
    if not proxy:
        proxy = safe_get(app.state.config, "preferences", "proxy")
        proxy = safe_get(provider, "preferences", "proxy", default=proxy)

    result = await _perform_channel_test_request(
        app=app,
        engine=engine,
        provider=provider,
        api_key=selected_api_key,
        model=model,
        upstream_model_hint=upstream_model_hint,
        timeout=timeout,
        proxy=proxy,
    )

    # 兼容旧前端：失败也返回 200，但 success=false
    return JSONResponse(status_code=200, content=result)


@router.post("/v1/channels/test_api_keys", dependencies=[Depends(rate_limit_dependency)])
async def test_channel_api_keys(
    token: str = Depends(verify_admin_api_key),
    test_config: dict = Body(..., description="Batch api key test config")
):
    """批量测试渠道内 API Key。

    典型用途：前端“一键测试全部 Key / 自动禁用失效 Key”。

    请求体示例：
    {
      "provider_snapshot": {...},
      "engine": "openai",
      "model": "gpt-4o-mini",
      "timeout": 30,
      "concurrency": 3,
      "api_keys": [{"index": 0, "key": "sk-xxx"}, ...]
    }
    """

    import asyncio
    from core.utils import get_model_dict

    app = get_app()

    provider_snapshot = test_config.get("provider_snapshot")
    provider = copy.deepcopy(provider_snapshot) if isinstance(provider_snapshot, dict) else {}
    if not isinstance(provider, dict):
        provider = {}

    engine = (
        test_config.get("engine")
        or provider.get("engine")
        or test_config.get("type")
        or "openai"
    )
    engine = str(engine).strip() if engine is not None else "openai"

    model = test_config.get("model")
    model = str(model).strip() if model is not None else ""
    if not model:
        raise HTTPException(status_code=400, detail="model 是必填项")

    upstream_model_hint = test_config.get("upstream_model")
    upstream_model_hint = str(upstream_model_hint).strip() if upstream_model_hint else None

    timeout = test_config.get("timeout", 30)
    try:
        timeout = max(1, int(timeout))
    except Exception:
        timeout = 30

    concurrency = test_config.get("concurrency", 3)
    try:
        concurrency = max(1, min(10, int(concurrency)))
    except Exception:
        concurrency = 3

    channel = get_channel(engine)
    if not channel:
        raise HTTPException(status_code=404, detail=f"Channel type '{engine}' not found")

    provider["provider"] = provider.get("provider") or f"test_{engine or 'channel'}"
    provider["engine"] = engine

    base_url = test_config.get("base_url") or provider.get("base_url", "")
    base_url = str(base_url).strip() if base_url else ""
    if not base_url:
        if channel.default_base_url:
            base_url = channel.default_base_url
        else:
            raise HTTPException(status_code=400, detail="base_url 是必填项（该渠道类型没有默认地址）")

    if not base_url.startswith(("http://", "https://")):
        base_url = f"https://{base_url}"
    provider["base_url"] = base_url.rstrip('/')

    provider_models = provider.get("model")
    if not isinstance(provider_models, list):
        fallback_models = provider.get("models")
        provider_models = copy.deepcopy(fallback_models) if isinstance(fallback_models, list) else []
    if not provider_models:
        if upstream_model_hint and upstream_model_hint != model:
            provider_models = [{upstream_model_hint: model}]
        else:
            provider_models = [model]
    provider["model"] = provider_models
    provider.pop("models", None)

    model_dict = get_model_dict(provider)
    if model not in model_dict:
        if upstream_model_hint and upstream_model_hint != model:
            provider["model"].append({upstream_model_hint: model})
        else:
            provider["model"].append(model)
        model_dict = get_model_dict(provider)

    provider["_model_dict_cache"] = model_dict

    if model not in model_dict:
        raise HTTPException(status_code=400, detail=f"model '{model}' 不在当前渠道模型配置中")

    proxy = test_config.get("proxy")
    if not proxy:
        proxy = safe_get(app.state.config, "preferences", "proxy")
        proxy = safe_get(provider, "preferences", "proxy", default=proxy)

    raw_api_keys = test_config.get("api_keys")
    if not isinstance(raw_api_keys, list) or not raw_api_keys:
        raise HTTPException(status_code=400, detail="api_keys 不能为空（格式：[{index, key}, ...]）")

    normalized: list[dict] = []
    for item in raw_api_keys:
        if isinstance(item, dict):
            idx = item.get("index")
            key = item.get("key")
        else:
            idx = None
            key = item

        try:
            idx = int(idx) if idx is not None else None
        except Exception:
            idx = None

        if not isinstance(key, str) or not key.strip():
            continue
        key = key.strip()
        if key.startswith("!"):
            key = key[1:]

        normalized.append({"index": idx, "key": key})

    if not normalized:
        raise HTTPException(status_code=400, detail="api_keys 全部为空")

    sem = asyncio.Semaphore(concurrency)

    async def _run_one(item: dict) -> dict:
        async with sem:
            key = item.get("key")
            idx = item.get("index")
            # 避免多任务共享同一个 provider 实例
            p = copy.deepcopy(provider)
            p["api"] = key
            result = await _perform_channel_test_request(
                app=app,
                engine=engine,
                provider=p,
                api_key=key,
                model=model,
                upstream_model_hint=upstream_model_hint,
                timeout=timeout,
                proxy=proxy,
            )
            result.update({
                "index": idx,
                "key_masked": _mask_api_key(key),
            })
            return result

    results = await asyncio.gather(*[_run_one(item) for item in normalized])

    return JSONResponse(content={
        "success": True,
        "engine": engine,
        "model": model,
        "results": results,
    })


@router.post("/v1/channels/models_by_groups", dependencies=[Depends(rate_limit_dependency)])
async def get_models_by_groups(
    token: str = Depends(verify_admin_api_key),
    request_body: dict = Body(..., description="Request body containing groups array")
):
    """
    根据分组获取可用的模型列表。
    
    请求体示例:
    {
        "groups": ["default", "premium"]  // 分组数组
    }
    
    返回:
    {
        "models": [
            {"id": "gpt-4o", "object": "model", "owned_by": "Zoaholic"},
            ...
        ]
    }
    """
    from core.utils import get_model_dict
    
    app = get_app()
    config = app.state.config
    providers = config.get("providers", [])
    
    # 获取请求的分组
    requested_groups = request_body.get("groups", [])
    if isinstance(requested_groups, str):
        requested_groups = [requested_groups]
    if not requested_groups:
        requested_groups = ["default"]
    
    allowed_groups = set(requested_groups)
    
    # 收集符合分组条件的模型
    all_models = []
    unique_models = set()
    
    for provider in providers:
        # 检查渠道是否启用
        if provider.get("enabled") is False:
            continue
        
        # 分组过滤：provider 必须与请求的分组有交集
        p_groups = provider.get("groups") or ["default"]
        if isinstance(p_groups, str):
            p_groups = [p_groups] if p_groups else ["default"]
        if not isinstance(p_groups, list) or not p_groups:
            p_groups = ["default"]
        
        if not allowed_groups.intersection(set(p_groups)):
            continue
        
        # 获取模型字典
        model_dict = provider.get("_model_dict_cache") or get_model_dict(provider)
        
        # 识别被重定向的上游原名（在此渠道内，出现在映射值中且与键不同的项）
        # 例如: {"pro": "pro", "pronothink": "pro"} 中，"pro" 作为值被 "pronothink" 重定向
        # 所以应该过滤掉 "pro"，只保留 "pronothink"
        redirected_upstreams = {v for k, v in model_dict.items() if v != k}
        
        # 如果渠道配置了 model_prefix，只展示带前缀的模型名
        prefix = provider.get('model_prefix', '').strip()
        
        for alias, upstream in model_dict.items():
            # 如果别名同时也是其他映射的上游目标，说明它被重定向了，跳过
            if alias in redirected_upstreams:
                continue
            # 如果有前缀，只返回带前缀的模型名
            if prefix and not alias.startswith(prefix):
                continue
            
            if alias not in unique_models:
                unique_models.add(alias)
                model_info = {
                    "id": alias,
                    "object": "model",
                    "created": 1720524448858,
                    "owned_by": "Zoaholic"
                }
                all_models.append(model_info)
    
    # 按模型名排序
    all_models.sort(key=lambda x: x["id"])
    
    return JSONResponse(content={"models": all_models})